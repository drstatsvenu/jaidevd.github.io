{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Continuous Integration for Data Scientsts</center></h1>\n",
    "<h2><center>by Jaidev Deshpande</center></h2>\n",
    "<h3><center>Data Scientist @ Cube26 Software Pvt Ltd</center></h3>\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "<div id=\"social\">\n",
    "<div id=\"social_twitter\">\n",
    "    <a href=\"http://twitter.com/jaidevd\"><img src=\"images/twitter-128.png\" width=\"32\" height=\"32\">\n",
    "    </a>\n",
    "</div>\n",
    "<div id=\"social_medium\">\n",
    "    <a href=\"http://medium.com/@jaidevd\"><img src=\"images/medium.ico\" width=\"32\" height=\"32\"></a>\n",
    "</div>\n",
    "<div id=\"social_github\">\n",
    "    <a href=\"http://github.com/jaidevd\"><img src=\"images/mark-github-128.png\" width=\"32\" height=\"32\"></a>\n",
    "</div>\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center\"><font size=\"4\"><strong>@jaidevd</strong></font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# From Peter Norvig's Q&A session on Quora:\n",
    "> I think that it will be important for machine learning experts and software engineers to come together to develop best practices for software development of machine learning systems. Currently we have a software testing regime where you define unit tests... We will need new testing processes that involve running experiments, analyzing the results... This is a great area for software engineers and machine learning people to work together to build something new and better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Recently Peter Norvig was asked in a Q&A what he thinks about the place of software developers in machine learning research. And this is his answer. \"We need new testing processes that involve running experiments and analyzing results\" and that \"this is a great area for developers and ML expers to work together\". The interesting thing here is that Norvig is talking about testing not as quality control, but as a way of evaluating machine learning models. So this idea is what I'm going to speak about, today. When I say CI, I don't literally mean CI. CI is a placeholder term for CI systems, devops, build, test and QA systems - and also the culture and habits that come with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# About me:\n",
    "\n",
    "* Data Scientist @Cube26 Software Pvt Ltd\n",
    "* Regular contributor to SciPy Stack\n",
    "* Helped develop the Canopy Data Analysis Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Typical Data Processing Pipeline\n",
    "![](images/flowchart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "So this here is a very broadly representative, a very general data processing pipeline. That box you see is known as ETL (extract-transform and load) part of the pipeline. You start with a source datastore, and end up in a sink datastore. The ETL part of the process is the most data-intensive one - by that I don't mean that others are not, it's just that this is the part where you treat your data for what it is - raw data. After it's left this box, it's no longer raw data, it's features, it's model coefficients, it's statistics, and so on. And it is in this box that your developer side has to be the most creative, as against your data scientist side, which has to show off outside the box. So after you've extracted, transformed and loaded your data, you train some model on it, and you do some validation which might allow you to do better model selection. These steps - training, validation and model selection - are not necessarily well separated in time. You could be cross-validating one model while you are already training another model, and a third one could actually be in production that is writing the output to whatever your sink is. So the idea is to stop thinking of this as a pipeline. How do you bend the spoon? Think that there is no spoon. So there is no such pipeline, and each of these blocks are independent systems - which only happen to be loosely coupled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using Data Abstractions\n",
    "## And Data Ingest as an abstraction\n",
    "![](images/wc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This is a word cloud of the text of all the proposals made to PyCon. As a species, I think we are spending an enormous amount of time and money beating data into shape. That's what almost all our conferences are about. Although I cannot justify this, I have a feeling that that is really overkill. I feel like dealing with data should be easier.\n",
    "\n",
    "I've met people who very sincerely believe that if they can get a lot of data accumulated in one place, it will automatically start becoming sentient. And this is for no fault of their own. This is clearly ridiculous. Data may not be sentient, but there certainly are some advantages to thinking about it as a living entity - in that it needs to be grown and cultivated before it is harvested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using Data Abstractions\n",
    "<div id=\"data_min_farm\">\n",
    "<div id=\"data_min_farm_min\">\n",
    "    <img src=\"images/mining.jpg\">\n",
    "</div>\n",
    "<h3><center>vs</center></h3>\n",
    "<div id=\"data_min_farm_farm\">\n",
    "    <img src=\"images/farming.jpg\">\n",
    "</div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "So instead of data mining, let's start speaking in terms of data farming. And here are a few ways of doing that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using Data Abstractions\n",
    "## And Data Ingest as an abstraction\n",
    "\n",
    "<ul>\n",
    "    <li><h3>Raw data is an integral part of ETL and therefore of your software</h3></li>\n",
    "    <li><h3>Working off local flatflies is <em>bad</em>!</h3></li>\n",
    "    <li><h3>Learn to work from remote storage to remote storage. Use the \"cloud\".</h3></li>\n",
    "    <li><h3>What about experimental / exploratory work? Use things like sqlite!</h3></li>\n",
    "    <li><h3>Only use local files when:</h3></li>\n",
    "    <ul>\n",
    "        <li><h3>doing EDA or any interactive studies.</h3></li>\n",
    "        <li><h3>debugging a larger application.</h3></li>\n",
    "        <li><h3>prototyping (resist the temptation to deploy).</h3></li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Abstract away almost everything that has to do with ETL. We haven't done that in a long time. Machine learning systems have grown super sophisticated while data management systems (that these same machine learning systems use), have trudged behind. Let's stop thinking of raw data as an inanimate entity that you only have to dig through before you can get the gold. The digging itself is part of your software, and is subject to pretty much the same dangers as any other kind of software development. So build abstraction layers, services and all kinds of tooling that you would need around ETL. Now this might sound very obvious, but you'd be surprised at how infrequently we practice this. For example, almost all development data scientists do is based off local flatfiles. The excuse is that they're just building prototypes and it's not really their job to have to deploy their models on larger systems. But we know how fast the boundaries between data scientists and other kinds of developers are thinning. In that light, we have to learn to work with larger more intergated data sources. Even if you're just building a prototype, this is still not every healthy because you have no idea how long the prototyping is going to take, or how many intermediate files you might end up producing. So, at least as a favour to people who are deploying your work to larger systems, learn to use larger integrated systems. Even if you're using the Iris dataset, try to use sqlite instead of CSV. The cloud is your friend. The sooner you become comfortable with remote or cloud based distributed storages, the faster you can deploy your apps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Ingest Libraries\n",
    "\n",
    "<ul>\n",
    "    <li><h3>sputnik: managing data packages and ML models</h3></li>\n",
    "    <li><h3>datreant - Using the local filesystem</h3></li>\n",
    "    <ul>\n",
    "        <li><h3>heterogenous data</h3></li>\n",
    "        <li><h3>many parameters, many files - lot of mess</h3></li>\n",
    "        <li><h3>datreant exploits this mess as flexibility, discoverability</h3></li>\n",
    "    </ul>\n",
    "    <li><h3>conduit: data exchange for HPC</h3></li>\n",
    "    <ul>\n",
    "        <li><h3>in-memory exchange & file-based exchange of data</h3></li>\n",
    "        <li><h3>JSON schema to describe and annotate data</h3></li>\n",
    "    </ul>\n",
    "    <li><h3>pysemantic: automate the validation and cleaning of dataset</h3></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "And here are a few libraries that can help you do that. So Sputnik is a library that manages data packages. You take a directory with your data in it, add a json that describing that directory and Sputnik will make a tarball out of it, allowing you to deal with the whole thing in a very atomic manner. Datreant is another data management library that leverages the local filesystem itself. It's common to have a very messy filesystem, but datreant will exploit this mess to provide some sort of discoverability into your data. You can think of it as a tradeoff between the simplicity of rigid file structure and the heterogenous data storage functionality that your filesystem can provide. Then there is conduit - which is used for managing data for HPC simulations. It is essentially a data model for describing hierarchical datasets. So it represents your data as a graph - and this graph integrates seamlessly with the in-memory data, serialized on-disk data, etc. Finally there is PySemantic by yours truly - which automates all the pandas code you would write for validating and cleaning your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Note about the AutoML project\n",
    "![](images/automl.png)\n",
    "<h4><i>\"If machine learning is so ubiquitous, one should just be able to use it without understanding libraries.\"</i></h4>\n",
    "<h4>- Andreas Mueller @ SciPy US 2016</h4>\n",
    "\n",
    "<li><h3>sklearn philosophy: explicit is better than implicit. DevOps philosophy - Just build and run stuff!</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "About two years ago I used to work on the Enthought Python Distribution, or Canopy. I was briefly a part of the buildsystem team that was responsible for making Python packages that would work across many platforms and architectures reliably. One rule of thumb that the buildsystem team had was that _upstream is always broken_. If you built a Python package as-is from its source code repository - it was very likely that it would be broken for some platform. So we used to write our own patches to fix that. We had patches for almost every project which we would apply and then build the packages before distributing them. Sklearn is one precious few projects which did not require a patch. It's a wonderful library that you really should study. Like requests, its one of those projects that are an example of what good Python development should be like. So it's very natural that sklearn follows the Zen of Python. So an sklearn developer would say that explicit is better than implicit. But a devops person would say, _is it really_? For sysadmins, things are so automated that its impossible to make them reasonably explicit. In fact, most sysadmins are reluctant even to update libraries lest it break something else. This is one of the reasons why enterprise Linux distros have outdated libraries. They just care about building and running stuff - which is another reason why projects like AutoML are useful. They allow you to run _a lot_ of models easily and in a hands-off manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Note about the AutoML project\n",
    "<ul>\n",
    "    <li><h3>Formalize the search space mindfully - discrete or continuous? Conditional parameters?</h3></li>\n",
    "    <li><h3>Automate:</h3></li>\n",
    "    <ul>\n",
    "        <li><h3>Choice of classification/regression algorithm</h3></li>\n",
    "        <li><h3>feature extraction & preprocessing</h3></li>\n",
    "        <li><h3>hyperparameter tuning</h3></li>\n",
    "    </ul>\n",
    "    <li><h3>Randomized & Grid Search are both embarassingly parallel</h3></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Automating Model Selection\n",
    "## Automating Cross Validation and Hyperparameter Tuning\n",
    "\n",
    "```python\n",
    "class CrossValidationTask(luigi.Task):\n",
    "    \n",
    "    estimator = luigi.Parameter() # or luigi.Target\n",
    "    \n",
    "    def run(self):\n",
    "        # Run CV loop\n",
    "        # Export metrics for each iteration\n",
    "\n",
    "\n",
    "class GridSearchTask(luigi.Task):\n",
    "    \n",
    "    grid = luigi.Parameter() # or Target\n",
    "    estimator = luigi.Parameter() # or Target\n",
    "    ...\n",
    "    \n",
    "    def run(self):\n",
    "        X, y = self.input()\n",
    "        clf = GridSearchCV(self.estimator, param_grid=self.grid, ...)\n",
    "        clf.fit(X, y)\n",
    "        ...\n",
    "        joblib.dump(clf.best_estimator_, self.output())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data and Model _Quality_\n",
    "\n",
    "## (Tools from psychometrics for) data quality evaluation\n",
    "### - Katie Malone @ SciPy US 2016\n",
    "\n",
    "<ul>\n",
    "    <li><h3>Predictive modeling != building a model</h3></li>\n",
    "    <li><h3>Iterative model selection involves going all the way back to data quality, not simply changing the pipeline</h3></li>\n",
    "    <li><h3>Develop the same intuition for your data as that for your model</h3></li>\n",
    "    <ul>\n",
    "        <li><h3>complex model + mediocre dataset = fair predictive accuracy</h3></li>\n",
    "        <li><h3>simple model + great dataset = high predictive accuracy</h3></li>\n",
    "    </ul>\n",
    "    <li><h3>Build many models for the same dataset and aggregate the metrics</h3></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data and model _Quality_\n",
    "## Communicating model results\n",
    "### - Bargava Subramanian @ SciPy US 2016\n",
    "\n",
    "<ul>\n",
    "    <li><h3>Performance metrics aren't as important as insights</h3></li>\n",
    "    <li><h3>Modularize and abstract away:</h3></li>\n",
    "    <ol>\n",
    "        <li><h3>raw data behaviour</h3></li>\n",
    "        <li><h3>visualization</h3></li>\n",
    "        <li><h3>learning and metrics</h3></li>\n",
    "    </ol>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Visualizing (Data & ML performance)\n",
    "\n",
    "<ul>\n",
    "        <li><h3>Bokeh server for dashboards</h3></li>\n",
    "        <li><h3>Chaco / Traits-based visualizations - for interative exploration</h3></li>\n",
    "        <li><h3>Use libs like Seaborn for stats - resist the temptation to write them yourself</h3></li>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exposing Trained Models\n",
    "\n",
    "<ul>\n",
    "        <li><h3>Simple serialization methods</h3></li>\n",
    "        <li><h3>sklearn-compiledtrees</h3></li>\n",
    "        <li><h3>Don't use nonlinear models where linear models will do</h3></li>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exposing Trained Models - The Serverless Paradigm\n",
    "\n",
    "> Most MLaaS products don’t allow much personalisation.\n",
    "This is why the Data Science community is still “stuck” to designing ad-hoc models with lower-level tools and frameworks. Which is great. Except that most of the time these ad-hoc models are developed by data scientists and tend to get stuck at the prototyping level. The outcome of this process will require a huge effort by some other developer or engineer, who probably can’t speak the data science language.\n",
    "\n",
    "> What if prototypes developed by data scientists were production-ready without any further effort?\n",
    "\n",
    "\\- Alex Casalboni\n",
    "(PyCon Italia 2015)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exposing Trained Models - The Serverless Paradigm\n",
    "<ul>\n",
    "        <li><h3>Simple serialization methods - are not infrastructure aware</h3></li>\n",
    "        <li><h3>HTTP API? Authentication?</h3></li>\n",
    "        <li><h3>Deployment Strategies:</h3></li>\n",
    "        <ol>\n",
    "        <li><h4>Simple flask wrappers - what about model updates?</h4>\n",
    "        <li><h4>Backend scaling? No elasticity!</h4>\n",
    "        <li><h4>AWS Lambda / Amazon API Gateway - Just use a set of functions that are automatically deployed and scaled</h4>\n",
    "        </ol>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "From https://blog.alexcasalboni.com/serverless-computing-machine-learning-baf52b89e1b0#.y36241bga\n",
    "\n",
    "More slides: http://www.slideshare.net/AlexCasalboni/how-to-deploy-machine-learning-models-in-the-cloud\n",
    "\n",
    "video: https://www.youtube.com/watch?v=YsyL-3CJ9GU"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
